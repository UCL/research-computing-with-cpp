




<!DOCTYPE html>
<!--[if IE 7]> <html lang="en" class="lt-ie9 lt-ie8 no-js"> <![endif]-->
<!--[if IE 8]> <html lang="en" class="lt-ie9 no-js"> <![endif]-->
<!--[if gt IE 8]><!--> <html lang="en" class="no-js"> <!--<![endif]-->
<head>
    <meta charset=utf-8 />
    <meta name="author" content="UCL" />
    <meta name="description" content="UCL Homepage" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <!-- social meta -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@uclnews">
    <meta name="twitter:title" content="UCL - London's Global University">
    <meta name="twitter:description" content="UCL (University College London) is London's leading multidisciplinary university, with 8,000 staff and 25,000 students.">
    <meta name="twitter:creator" content="@UCLWAMS">
    <meta name="twitter:image:src" content="http://www.ucl.ac.uk/visual-identity/logos/standalone.png">
    <meta property="og:image" content="http://www.ucl.ac.uk/visual-identity/logos/standalone.png" />
    <meta property="og:title" content="UCL - London's Global University" />
    <meta property="og:url" content="http://www.ucl.ac.uk" />
    <meta property="og:site_name" content="UCL" />
    <meta property="og:description" content="UCL (University College London) is London's leading multidisciplinary university, with 8,000 staff and 25,000 students." />
    <meta property="og:type" content="website" />
    <meta property="og:profile_id" content="uclofficial" />
    <!-- end social meta -->

  <title>Memory</title>

  <link href="/research-computing-with-cpp/assets/css/screen.min.css" media="screen, projection" rel="stylesheet" type="text/css" />
  <link href="/research-computing-with-cpp/assets/css/jekyll-styles.css" rel="stylesheet" type="text/css">
  <link href="/research-computing-with-cpp/site-styles/local_styles.css" rel="stylesheet" type="text/css">
  <link href="/research-computing-with-cpp/site-styles/ipython.css" rel="stylesheet" type="text/css">

  <link rel="shortcut icon" href="/research-computing-with-cpp/assets/images/favicon.ico" />
    <link rel="apple-touch-icon-precomposed" href="/research-computing-with-cpp/favicon-152.png">
    <meta name="msapplication-TileColor" content="#000000">
    <meta name="msapplication-TileImage" content="/research-computing-with-cpp/favicon-144.png">

  <script src="/research-computing-with-cpp/assets/js/lib/modernizr-custom.js"></script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>

    <script>
      var cuttingTheMustard = document.querySelector && window.localStorage && window.addEventListener;

      Modernizr.load({
        //cutting the mustard as used by the BBC
        test: cuttingTheMustard
        //if old browser load the shiv
        ,
        nope: [
          '/research-computing-with-cpp/assets/js/lib/html5shiv-printshiv.min.js', '/research-computing-with-cpp/assets/js/lib/respond.min.js'
        ]
      });
      //set conditional assets for main.js
      var globalSiteSpecificVars = {
        pathToJquery: "/research-computing-with-cpp/assets/js/lib/jquery-1.9.1.min",
        googleAnalyticsIdsArray: [] //specify array of site specific id's NOT UCL generic UA-943297-1
      }
      if (cuttingTheMustard) {
        globalSiteSpecificVars.pathToJquery = '/research-computing-with-cpp/assets/js/lib/jquery-2.1.1.min';
      }
    </script>
    <script src="/research-computing-with-cpp/assets/js/lib/require.min.js"></script>
    <script src="/research-computing-with-cpp/assets/js/main.js"></script>
    <script>
      require.config({
        baseUrl: '/research-computing-with-cpp/assets/js/lib'
      });
        require(["app/general", "app/searchWithAutoComplete", "app/tabs"]);//load the default stuff
    </script>
</head>

<body id="index" class="layout-vertical layout-vertical--nav-1col">

  <header class="header header--desktop">

  <a class="header__close" href="#">
    <img src="/research-computing-with-cpp/assets/images/close.png" class="lazy" data-src="//static.ucl.ac.uk/indigo/images/close.png" alt="X" />Close</a>

  <div class="masthead">

  <div class="wrapper clearfix">

      <div class="masthead__search">
					<form action="#" method="get">
						<div class="search-form">
							<input type="search" placeholder="Search UCL websites, degrees, short courses, people and more" aria-label="Search UCL websites, degrees, short courses" class="search-form__input search-form__input--search tt-input" name="query" value="" autocomplete="off" spellcheck="false" dir="auto" style="position: relative; vertical-align: top;">
						</div>
						<input type="submit" name="submit" value="Go" class="btn btn--primary search-form__input search-form__input--submit">

					</form>
				</div>


				<nav class="masthead__nav m-clear">
					<ul class="masthead__list">
						<li class="masthead__item"><a href="//www.ucl.ac.uk/prospective-students" title="" class="masthead__link">Study</a>
						</li>
						<li class="masthead__item"><a href="//www.ucl.ac.uk/research" title="" class="masthead__link">Research</a>
						</li>
						<li class="masthead__item"><a href="//www.ucl.ac.uk/engage" title="" class="masthead__link">Engage</a>
						</li>

						<li class="masthead__item"><a href="//www.ucl.ac.uk/about" title="" class="masthead__link">About</a>
						</li>

						<li class="masthead__item"><a href="//www.ucl.ac.uk/giving" title="" class="masthead__link give-link">Give</a>
						</li>
					</ul>
				</nav>
			</div>

</div><!-- end .masthead -->


  <div class="wrapper">

    <div class="photograph">
  <div class="brand">
    <p class="brand__heading">COMP0210: Research Computing with C++</p>
    <a href="/" class="brand__link"><span class="visually-hidden">Home</span></a>
    <img src="//cdn.ucl.ac.uk/img/blank.gif" data-src="//static.ucl.ac.uk/indigo/images/ucl-logo.svg" alt="UCL logo" id="logo" class="brand__logo lazy">  
  </div>
</div>


    <div class="sidebar">

      <nav class="nav nav--mobile">
        <ul>
          

 <li class="active"> <a href="/research-computing-with-cpp/01projects/">Introduction to C++</a><ul><li class="inactive"> <a href="/research-computing-with-cpp/01projects/sec01Git.html">Version control with Git</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/01projects/sec02IntroToCpp.html">Introduction to C++</a> </li> </ul> </li><li class="active"> <a href="/research-computing-with-cpp/02cpp1/">Week 2: Custom Data Types and (a glimpse of) the Standard Library</a><ul><li class="inactive"> <a href="/research-computing-with-cpp/02cpp1/sec01Types.html">Types</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/02cpp1/sec02PassByValueOrReference.html">Pass by Value and Pass by Reference</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/02cpp1/sec03ObjectOrientedProgramming.html">Object Oriented Programming</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/02cpp1/sec04StandardLibrary.html">C++ Standard Library</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/02cpp1/sec05Pointers.html">Pointers in C++</a> </li> </ul> </li><li class="active"> <a href="/research-computing-with-cpp/03cpp2/">Week 3: Error Handling and C++ Projects</a><ul><li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec01Exceptions.html">Exceptions</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec02ErrorHandling.html">Other Error Mechanisms</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec03CMakeBasics.html">CMake Basics</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec04UnitTesting.html">Testing Software</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec05SoftwareBuilds.html">Building research software</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec06CMakeBackground.html">CMake Background</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec07CMakeHelloWorld.html">HelloWorld with CMake</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec08BuildHelloWorld.html">Building 'HelloWorld'</a> </li> </ul> </li><li class="active"> <a href="/research-computing-with-cpp/04cpp3/">Week 4: Polymorphism</a><ul><li class="inactive"> <a href="/research-computing-with-cpp/04cpp3/sec01Inheritance.html">Inheritance</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/04cpp3/sec03Templates.html">Templates</a> </li> </ul> </li> <li class="active"> <a href="/research-computing-with-cpp/05libraries/">Week 5: Code Design and Programming Paradigms</a><ul> <li class="inactive"> <a href="/research-computing-with-cpp/05libraries/ProgrammingParadigms.html">Programming Paradigms</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/05libraries/sec01DesigningClasses.html">Designing Classes and Code</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/05libraries/sec03CppCodeDesign.html">C++ Code Design Summary</a> </li> </ul> </li><li class="active"> <a href="/research-computing-with-cpp/06tooling/">Week 6: Libraries and Tooling</a><ul> <li class="inactive"> <a href="/research-computing-with-cpp/06tooling/sec00TimingAndTooling.html">Timing and Tooling</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/06tooling/sec01ChoosingLibraries.html">Choosing Libraries</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/06tooling/sec02LibraryBasics.html">Library Basics</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/06tooling/sec03LinkingLibraries.html">Linking Libraries</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/06tooling/sec04InstallingLibraries.html">Installing Libraries</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/06tooling/sec05Summary.html">Summary</a> </li></ul> </li> <li class="active"> <a href="/research-computing-with-cpp/07performance/">Week 7: Introduction to Performance</a><ul> <li class="active"> <a href="/research-computing-with-cpp/07performance/sec00Motivation.html">Why Optimise for Performance?</a> </li> <li class="active"> <a href="/research-computing-with-cpp/07performance/sec01Complexity.html">Computational Complexity</a> </li> <li class="active"> <a href="/research-computing-with-cpp/07performance/sec02Memory.html">Memory</a> </li> <li class="active"> <a href="/research-computing-with-cpp/07performance/sec03Optimisation.html">Compiler Optimisation</a> </li> </ul> </li><li class="active"> <a href="/research-computing-with-cpp/08openmp/">Week 8: Parallel Programming with OpenMP</a><ul><li class="inactive"> <a href="/research-computing-with-cpp/08openmp/01_parallel_programming.html">What is parallel programming?</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/08openmp/02_intro_openmp.html">An introduction to OpenMP</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/08openmp/04_cache_performance.html">Cache Performance in Shared Memory</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/08openmp/05_summary.html">Summary</a> </li></ul> </li> <li class="active"> <a href="/research-computing-with-cpp/09distributed_computing/">Week 9: Distributed Memory Parallelism</a><ul><li class="inactive"> <a href="/research-computing-with-cpp/09distributed_computing/sec01DistributedMemoryModels.html">Distributed Memory Model</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/09distributed_computing/sec02ProgrammingWithMPI.html">MPI Programming</a> </li> </ul> </li> <li class="active"> <a href="/research-computing-with-cpp/10parallel_algorithms/">Week 10: Work Depth Models and Parallel Strategies</a><ul> <li class="inactive"> <a href="/research-computing-with-cpp/10parallel_algorithms/AsynchronousMPI.html">Asynchronous MPI Programs</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/10parallel_algorithms/WorkDepth.html">Work Depth Models and Parallel Strategy</a> </li></ul> </li> 

        </ul>
      </nav>

      <nav class="nav nav--left">
        <ul>
          

 <li class="active"> <a href="/research-computing-with-cpp/01projects/">Introduction to C++</a><ul><li class="inactive"> <a href="/research-computing-with-cpp/01projects/sec01Git.html">Version control with Git</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/01projects/sec02IntroToCpp.html">Introduction to C++</a> </li> </ul> </li><li class="active"> <a href="/research-computing-with-cpp/02cpp1/">Week 2: Custom Data Types and (a glimpse of) the Standard Library</a><ul><li class="inactive"> <a href="/research-computing-with-cpp/02cpp1/sec01Types.html">Types</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/02cpp1/sec02PassByValueOrReference.html">Pass by Value and Pass by Reference</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/02cpp1/sec03ObjectOrientedProgramming.html">Object Oriented Programming</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/02cpp1/sec04StandardLibrary.html">C++ Standard Library</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/02cpp1/sec05Pointers.html">Pointers in C++</a> </li> </ul> </li><li class="active"> <a href="/research-computing-with-cpp/03cpp2/">Week 3: Error Handling and C++ Projects</a><ul><li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec01Exceptions.html">Exceptions</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec02ErrorHandling.html">Other Error Mechanisms</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec03CMakeBasics.html">CMake Basics</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec04UnitTesting.html">Testing Software</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec05SoftwareBuilds.html">Building research software</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec06CMakeBackground.html">CMake Background</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec07CMakeHelloWorld.html">HelloWorld with CMake</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec08BuildHelloWorld.html">Building 'HelloWorld'</a> </li> </ul> </li><li class="active"> <a href="/research-computing-with-cpp/04cpp3/">Week 4: Polymorphism</a><ul><li class="inactive"> <a href="/research-computing-with-cpp/04cpp3/sec01Inheritance.html">Inheritance</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/04cpp3/sec03Templates.html">Templates</a> </li> </ul> </li> <li class="active"> <a href="/research-computing-with-cpp/05libraries/">Week 5: Code Design and Programming Paradigms</a><ul> <li class="inactive"> <a href="/research-computing-with-cpp/05libraries/ProgrammingParadigms.html">Programming Paradigms</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/05libraries/sec01DesigningClasses.html">Designing Classes and Code</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/05libraries/sec03CppCodeDesign.html">C++ Code Design Summary</a> </li> </ul> </li><li class="active"> <a href="/research-computing-with-cpp/06tooling/">Week 6: Libraries and Tooling</a><ul> <li class="inactive"> <a href="/research-computing-with-cpp/06tooling/sec00TimingAndTooling.html">Timing and Tooling</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/06tooling/sec01ChoosingLibraries.html">Choosing Libraries</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/06tooling/sec02LibraryBasics.html">Library Basics</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/06tooling/sec03LinkingLibraries.html">Linking Libraries</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/06tooling/sec04InstallingLibraries.html">Installing Libraries</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/06tooling/sec05Summary.html">Summary</a> </li></ul> </li> <li class="active"> <a href="/research-computing-with-cpp/07performance/">Week 7: Introduction to Performance</a><ul> <li class="active"> <a href="/research-computing-with-cpp/07performance/sec00Motivation.html">Why Optimise for Performance?</a> </li> <li class="active"> <a href="/research-computing-with-cpp/07performance/sec01Complexity.html">Computational Complexity</a> </li> <li class="active"> <a href="/research-computing-with-cpp/07performance/sec02Memory.html">Memory</a> </li> <li class="active"> <a href="/research-computing-with-cpp/07performance/sec03Optimisation.html">Compiler Optimisation</a> </li> </ul> </li><li class="active"> <a href="/research-computing-with-cpp/08openmp/">Week 8: Parallel Programming with OpenMP</a><ul><li class="inactive"> <a href="/research-computing-with-cpp/08openmp/01_parallel_programming.html">What is parallel programming?</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/08openmp/02_intro_openmp.html">An introduction to OpenMP</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/08openmp/04_cache_performance.html">Cache Performance in Shared Memory</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/08openmp/05_summary.html">Summary</a> </li></ul> </li> <li class="active"> <a href="/research-computing-with-cpp/09distributed_computing/">Week 9: Distributed Memory Parallelism</a><ul><li class="inactive"> <a href="/research-computing-with-cpp/09distributed_computing/sec01DistributedMemoryModels.html">Distributed Memory Model</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/09distributed_computing/sec02ProgrammingWithMPI.html">MPI Programming</a> </li> </ul> </li> <li class="active"> <a href="/research-computing-with-cpp/10parallel_algorithms/">Week 10: Work Depth Models and Parallel Strategies</a><ul> <li class="inactive"> <a href="/research-computing-with-cpp/10parallel_algorithms/AsynchronousMPI.html">Asynchronous MPI Programs</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/10parallel_algorithms/WorkDepth.html">Work Depth Models and Parallel Strategy</a> </li></ul> </li> 

        </ul>
      </nav>

    </div>
    <!-- end .sidebar -->

    <nav class="nav nav--top">
      <ul>
        
      </ul>
    </nav>

  </div>
  <!-- end .wrapper -->

  </header>
  <!-- end .header -->

  <div class="site-content wrapper">

    <header class="header header--mobile default-header">
      <a class="header__open" href="#">
        <img src="/research-computing-with-cpp/assets/images/ucl-menu.svg" alt="Menu" />
      </a>
    </header>

    <div class="site-content__inner clearfix">
      <div class="site-content__body">

          
            <nav class="breadcrumb clearfix">
              <ul class="breadcrumb__list">
                <li class="breadcrumb__item"><a href="http://www.ucl.ac.uk/">UCL</a></li>

  
    <li class="breadcrumb__item"><a href="http://www.ucl.ac.uk/ISD">ISD</a></li>
  
    <li class="breadcrumb__item"><a href="http://www.ucl.ac.uk/isd/services">Our services</a></li>
  
    <li class="breadcrumb__item"><a href="http://www.ucl.ac.uk/isd/services/research-it">Research IT</a></li>
  
    <li class="breadcrumb__item"><a href="http://www.ucl.ac.uk/isd/services/research-it/training">Training</a></li>
  

<li class="breadcrumb__item"><a href="/research-computing-with-cpp/">COMP0210</a></li>



              </ul>
            </nav>
           <div class="site-content__main">
            
            
          
          

    <p>Estimated Reading Time: 30 minutes</p>

<h1 id="memory">Memory</h1>

<p>Managing memory efficiently can be an important part of achieving peak performance. In this section we’ll talk a bit about the basic model of how data is stored and accessed, and what this means for software development.</p>

<h2 id="memory-bound-problems">Memory Bound Problems</h2>

<p>When considering the efficiency of solving a problem on a computer, two classifications can sometimes be useful:</p>

<ul>
  <li><strong>Compute bound</strong> problems are those for which the main work or primary bottleneck is the number of compute steps required to complete the algorithm. For example, performing lots of arithmetic operations on a piece of data.</li>
  <li><strong>Memory bound</strong> problems are those for which our main concern is the time spent accessing (reading or writing) memory. For example, copying or overwriting a large piece of data.</li>
</ul>

<p>A straight-forward example of a memory bound problem would be a matrix transposition, $M^T_{ij} = M_{ji}$. This problem doesn’t require any direct calculations to be done on the elements themselves, just to read the elements from one location and place them in another.</p>

<p>To keep things simple, let’s look at this “out of place” matrix transpose:</p>

<pre><code class="language-cpp=">void Transpose(vector&lt;vector&lt;float&gt;&gt; &amp;A, vector&lt;vector&lt;float&gt;&gt; &amp;B)
{
    int N = A.size();
    for(int i = 0; i &lt; N; i++)
    {
        for(int j = 0; j &lt; N; j++)
        {
            A[i][j] = B[j][i];
        }
    }
}
</code></pre>

<ul>
  <li>“Out of place” means that the result is placed in a new matrix rather than over-writing the original.</li>
  <li>This algorithm is almost entirely composed of memory read/write operations!</li>
  <li>In order to understand how to optimise a memory bound problem like this, we have to first understand the structure of memory in our machine.</li>
</ul>

<h2 id="the-memory-hierarchy">The Memory Hierarchy</h2>

<p>Data is stored in a computer in different forms and different places. Generally, the bigger your memory store, the slower it is to access! This trade-off is typical for developing on many architectures from PCs to specialised accelerated hardware. On a typical computer you’re likely to have:</p>

<ul>
  <li><strong>Persistent Memory</strong>
    <ul>
      <li>This is the largest store of data and includes things like your hard disk. Writing to this kind of memory has the highest overheads, but the data remains intact without power and is typically on the scale of tens of GB or more.</li>
    </ul>
  </li>
  <li><strong>System Memory</strong>
    <ul>
      <li>This includes on-chip RAM and ROM.</li>
      <li>ROM is permanent, and read-only, and generally not of much interest to software developers since it handles things like instructions for basic I/O and loading the operating system: things that we don’t (and can’t) mess with!</li>
      <li>RAM is generally volatile memory, meaning that it requires power to be maintained: if you turn off your computer you will typically lose what is in RAM. Usually on the scale of a few GB. Contains the current program and data in use.
        <ul>
          <li>Stack: Stack memory is usually $\lesssim 10$ MB, assigned by the operating system when the program is launched. Stack memory cannot be increased while the program is running. Contains data for currently open scopes i.e. the function currently being executed and any hierarchy of functions which are calling it and therefore have not terminated yet. Very large pieces of data or very deep call trees (e.g. excessively deep recursion) can cause a <em>stack overflow</em>, where the stack runs out of memory. Stack memory is generally faster than Heap memory.</li>
          <li>Heap: The Heap is a larger pool of memory, also assigned by the operating system at the program launch, but the heap size allocated to a program can grow dynamically as long as there is enough space left in RAM. Memory access tends to be slower than for the stack, but can be used for larger datasets.</li>
        </ul>
      </li>
      <li>Cache: Very small pieces of memory designed to be very fast. Cache structure is hardware dependent, but three levels of caching is typical, ranging from kB to MB (with the smallest cache layer being fastest to access). Cache memory stores chunks of data from locations accessed recently in memory.</li>
    </ul>
  </li>
</ul>

<p>This structure has implications for our understanding of memory bound problems:</p>

<ul>
  <li>Problems which use very large datasets may be more likely to be memory bound, as larger data stores are less efficient to access. Accesses to large stores should be minimised, and data being worked on should be moved to faster memory.</li>
  <li>Algorithms which jump around erratically in memory also result in slower memory accesses. Architectures are usually optimised for sequential or localised accesses to some extent, for example memory addresses close to those recently accessed are more likely to be in the cache.</li>
  <li>Working on a piece of data as fully as possible before accessing another location will limit the number of memory accesses over all.</li>
</ul>

<h2 id="cache-structure">Cache structure</h2>

<p>It’s not always possible to limit the number of memory accesses that we make, but we may be able to make choices about our memory access patterns to maximise our usage of our fastest memory. In this case, we’ll consider an example where our object is stored entirely in on-chip RAM, but we want to make effective use of the cache. First, we’ll need to understand a bit about how the cache works.</p>

<ul>
  <li>When data is requested, the cache is checked first to see if it is present. If it is, it can take the data straight from the cache, which is much faster than going into RAM.</li>
  <li>If there are multiple cache levels, it searches from the smallest (and fastest) cache to the largest (and slowest).</li>
  <li>If it’s not is any cache (a cache “miss”) it will fetch the value from RAM.</li>
  <li>When data is looked up in system memory, that data is stored in the cache.
    <ul>
      <li>If the cache is full or there is data already in the location that the system wants to cache the new data, then some data in the cache is overwritten. (Where the data is cached and therefore which data is overwritten depends on the cache-mapping strategy and will be hardware dependent.)</li>
    </ul>
  </li>
  <li>Data is added to the cache in blocks of a fixed size (which is hardware dependent). If the variable we wanted to read is smaller than this block size then some neighbouring data will end up in the cache as well.
    <ul>
      <li>If we read an element from an array or vector for example, which store data contiguously, that means that some surrounding elements will also end up in the cache.</li>
      <li>We can then read close by elements from the cache quickly without system memory accesses until you reach the limits of the copied block!</li>
    </ul>
  </li>
</ul>

<p>Taking advantage of these blocks of memory in the cache is the key to writing efficient memory bound algorithms: if we use them wisely we can avoid a lot of calls to system memory and replace them with much quicker calls to the cache.</p>

<h3 id="using-the-cache-effectively">Using the Cache effectively</h3>

<p>We know now that:</p>

<ul>
  <li>Reading the same memory address (e.g. accessing the same variable), or reading nearby memory addresses (e.g. elements in a vector) is faster than jumping around in memory.
    <ul>
      <li>This suggests that we should break problems down into sizes that will fit in the cache, and then work on them until we don’t need that data any more before moving on (if we can).</li>
    </ul>
  </li>
  <li>The structure and size of the cache, and the size of the blocks loaded into the cache from memory, are all system dependent.
    <ul>
      <li>This suggests that over-optimising for the cache is a bad idea: if we design code especially for the specifications of the cache on our machine, it will not be very portable to other machines! We should try to make algorithms that will exploit the cache well but are ideally not dependent on the exact size.</li>
    </ul>
  </li>
</ul>

<p>An algorithm which exploits the cache but which does not depend on the exact details of the cache is called a <em>cache oblivious algorithm</em>. Some good patterns for cache oblivious algorithms include:</p>

<ul>
  <li>Tiling: breaking the problem into small chunks.</li>
  <li>Recursion can be a good way to make your solution cache oblivious. Recursion expresses the solution in terms of solutions to smaller sub-problems, down to a base case. The cache will start to be used effectively once the size of the sub-problems start to fit inside the cache, which means you don’t have to tune the algorithm to the size of the cache to take advantage of it.</li>
  <li>Stencil algorithms are algorithms which calculate a value at a data point based on the values around it in a grid (common in simulations of e.g. flows) and fit naturally into efficient memory structures provided the stencil moves sensibly through memory.</li>
  <li>Rearrange data in memory to fit your access patterns. For example a matrix may be stored with elements in the same row next to each other (row major order) <em>or</em> with elements in the same column next to each other (column major order). Accessing memory in sequence will take advantage of your cache well regardless of the size of your cache.</li>
</ul>

<h2 id="efficiently-cached-algorithm-example-matrix-transposition">Efficiently Cached Algorithm Example: Matrix Transposition</h2>

<p>Let’s take a look again at our example of a memory bound problem, matrix transposition, and see how it can be impacted by good and bad use of the cache. Let’s start with our simple matrix transpose code and see how it might behave:</p>

<pre><code class="language-cpp=">void Transpose(vector&lt;vector&lt;float&gt;&gt; &amp;A, vector&lt;vector&lt;float&gt;&gt; &amp;B)
{
    int N = A.size();
    for(int i = 0; i &lt; N; i++)
    {
        for(int j = 0; j &lt; N; j++)
        {
            B[i][j] = A[j][i];
        }
    }
}
</code></pre>

<p>We’ll assume that our matrices are in row major order, so rows in each matrix are contiguous in memory, and we will be focusing just on reading the data from the source matrix, and ignoring writing the operations to the output matrix, since the output matrix will be filled in order so that part of the algorithm is already cache efficient. (If they were in column major order the logic would be the same except exchanging write for read: reading the source matrix would be cache efficient, but writing the output matrix would be inefficient.)</p>

<p>This is an illustrative example using a single cache of very small capacity; we won’t concern ourselves with the exact cache-mapping strategy since this varies, but will just fill in our cache in order. In the diagrams <em>red</em> blocks will be blocks in system memory but not in the cache, and <em>blue</em> blocks are data which are also stored in the cache.</p>

<ol>
  <li>
    <p>The first element we read is <code class="language-plaintext highlighter-rouge">A[0][0]</code>. Our cache is empty at the moment so this results in a cache miss.</p>

    <p><img src="img/CacheTranspose1.png" alt="image" /></p>
  </li>
  <li>
    <p>The block of data containing <code class="language-plaintext highlighter-rouge">A[0][0]</code> is therefore read from RAM and copied into the cache, which now also contains <code class="language-plaintext highlighter-rouge">A[0][1]</code> and <code class="language-plaintext highlighter-rouge">A[0][2]</code> etc.</p>

    <p><img src="img/CacheTranspose2.png" alt="image" /></p>
  </li>
  <li>
    <p>The next value we read is <code class="language-plaintext highlighter-rouge">A[1][0]</code>. This also results in a cache miss if the matrix is too large for more than one row to fit in a single block in the cache (which is likely as cache blocks are very small).</p>

    <p><img src="img/CacheTranspose3.png" alt="image" /></p>
  </li>
  <li>
    <p>The block containing <code class="language-plaintext highlighter-rouge">A[1][0]</code>, <code class="language-plaintext highlighter-rouge">A[1][1]</code> … is copied to the cache.</p>

    <p><img src="img/CacheTranspose4.png" alt="image" /></p>
  </li>
  <li>
    <p>This sequence of cache misses and copies continues and eventually the cache is filled.</p>

    <p><img src="img/CacheTranspose5.png" alt="image" /></p>
  </li>
  <li>
    <p>When we try to read the next element, we once again have a cache miss, but now in order to add it into the cache we must replace an earlier entry.</p>

    <p><img src="img/CacheTranspose6.png" alt="image" /></p>
  </li>
  <li>
    <p>Eventually we will have read through the entire first column, and will start on the second column to read <code class="language-plaintext highlighter-rouge">A[0][1]</code>. This was added into our cache in step 2, but if the matrix is sufficiently large (or if there are clashes because of the cache-mapping strategy) then by the time we return to read this value it will have been overwritten in the cache, resulting in yet another cache miss!</p>

    <p><img src="img/CacheTranspose7.png" alt="image" /></p>
  </li>
  <li>
    <p>This process continues on for the whole matrix, in this case missing the cache and making a call to system memory for every single element. Since this problem is clearly memory bound, this will have a large impact on the performance of this algorithm by slowing down all of our memory accesses.</p>

    <p><img src="img/CacheTranspose8.png" alt="image" /></p>
  </li>
</ol>

<p>We can solve this problem by dividing our matrix up into smaller sub-matrices which do fit into the cache. In this toy example where we only have four slots in our cache, we’ll just transpose the $4 \times 4$ sub-matrix $A_{0 … 3, 0…3}$. (In reality you can store more than this in a cache but then the diagram would get very cluttered indeed!)</p>

<ol>
  <li>
    <p>The algorithm will start as before, with a series of cache misses.</p>

    <p><img src="img/CacheTranspose9.png" alt="image" /></p>
  </li>
  <li>
    <p>However in this case we stop moving down the column before we overwrite any existing matrix data in our cache. So when we come to read <code class="language-plaintext highlighter-rouge">A[0][1]</code> it is still present in the cache! In fact the rest of this small matrix is cached, so we proceed with 12 cache hits after our first four cache misses: a major improvement in memory performance!</p>

    <p><img src="img/CacheTranspose10.png" alt="image" /></p>
  </li>
  <li>
    <p>We can then repeat this process for each small sub matrix within our main matrix and achieve the same ratio of hits to misses throughout.</p>
  </li>
</ol>

<h2 id="optional-note-virtual-memory-and-paging">Optional note: Virtual Memory and Paging</h2>

<p>Memory addresses used by pointers in C++ are in fact pointers to <em>virtual memory</em>: an abstract model of memory, but not the <em>physical</em> memory addresses themselves. This is important because the memory used by a program is actually set by the operating system (remember that your program is assigned stack and heap memory at the start), so in order for our program to work regardless of what memory space we’re given we can’t refer to explicit physical memory addresses. Instead it has to refer to these virtual memory addresses which are then translated into the real memory addresses by the OS. This can have some consequences because addresses which are contiguous in <em>virtual memory</em> are not necessarily contiguous in physical memory!</p>

<p>Memory (in RAM or on disk) is generally <em>paged</em>, which means stored in blocks of a particular size (4kB is common). Pages in virtual memory can be translated into pages in physical memory, with some overhead to resolve the page location and usually some latency to access it (which will depend on the kind of memory you are accessing). If a an area of virtual memory, for example storage of a vector, crosses more than one page, these pages may not be contiguous in physical memory (even if they are in virtual memory).</p>

<p>If your data is not well aligned with the pages, then you can end up doing unnecessary additional work to resolve extra pages. Similar to how cache efficient algorithms work, some algorithms (such as B-trees, see the <em>Introduction to Algorithms</em> book in the recommended texts for a great discussion of these!)) which deal with very large data on disk will work with one page at a time to minimise hopping from page to page. Sometimes alignment is even more important, as some accelerated devices require memory to be aligned with the pages in order to be streamed to / from the device. If the memory is not aligned, it can be copied into a new, aligned memory location which is expensive for large datasets. Page resolutions can also be made more efficient if we can force memory to be allocated contiguously in <em>physical memory</em>, which can also be useful for streaming to such devices.</p>

<p>If strictly necessary, these memory properties can be forced by using OS specific commands, although standard C++ does have methods for declaring aligned memory.
If you are interested, <a href="https://xilinx.github.io/Vitis-Tutorials/2022-1/build/html/docs/Hardware_Acceleration/Introduction/runtime_sw_design.html">here is an example for FPGAs</a>, a kind of accelerated hardware, with a discussion of these concepts and how to address them.</p>



        </div>

      </div>
    </div>

  </div>
  <!-- end .site-content -->

  <footer class="footer wrapper">
  <div class="footer__inner clearfix">
             <article class="block block--col-1">
                <h2 class="as-h5">Information for</h2>
                <ul class="footer__list list-unstyled">
					<li class="footer__item"><a href="//www.ucl.ac.uk/students">Current students</a></li>
					<li class="footer__item"><a href="//www.ucl.ac.uk/staff">Staff</a></li>
					<li class="footer__item"><a href="//www.ucl.ac.uk/alumni">Alumni</a></li>
					<li class="footer__item"><a href="//www.ucl.ac.uk/enterprise/businesses">Business</a></li>
					<li class="footer__item"><a href="//www.ucl.ac.uk/giving">Donors</a></li>
				</ul>
            </article>
            <article class="block block--col-2">
		<h2 class="as-h5">Visit</h2>
                <ul class="footer__list list-unstyled">
					<li class="footer__item"><a href="//www.ucl.ac.uk/maps">Maps</a></li>
					<li class="footer__item"><a href="//www.ucl.ac.uk/lccos/library-culture-collections-and-open-science-lccos">Library, museums and collections</a></li>
					<li class="footer__item"><a href="//www.ucl.ac.uk/bloomsbury-theatre">Bloomsbury Theatre</a></li>
					<li class="footer__item"><a href="//www.ucl.ac.uk/ucl-east">UCL East</a></li>
					<li class="footer__item"><a href="//www.ucl.ac.uk/maps">Tours and visits</a></li>

				</ul>
            </article>
            <article class="block block--col-3">
		<h2 class="as-h5">Connect with UCL</h2>
                <ul class="footer__list list-unstyled">
					<li class="footer__item"><a href="//www.ucl.ac.uk/work-at-ucl/search-ucl-jobs">Jobs</a></li>
					<li class="footer__item"><a href="//www.ucl.ac.uk/news/services-media">Media Relations</a></li>
					<li class="footer__item"><a href="//www.ucl.ac.uk/events">Events</a></li>
					<li class="footer__item"><a href="//www.ucl.ac.uk/london">UCL and London</a></li>
					<li class="footer__item"><a href="//shop.ucl.ac.uk">UCL Shop</a></li>
				</ul>

      </article>
<div class="clear"></div>
<ul id="social" class="list-inline footer__list list-unstyled zero-bottom">
  <li><a href="//twitter.com/ucl"><img class="zero-bottom" alt="Twitter" src="//cdn.ucl.ac.uk/img/twitter-x.png" height="35" width="35"></a></li>
  <li><a href="//www.facebook.com/uclofficial"><img class="zero-bottom" alt="Facebook" src="//cdn.ucl.ac.uk/img/35x35xfacebook.png.pagespeed.ic.-VUStBF1gm.png" height="35" width="35"></a></li>
  <li><a href="//www.youtube.com/ucltv"><img class="zero-bottom" alt="YouTube" src="//cdn.ucl.ac.uk/img/35x35xyoutube-icon-square.png.pagespeed.ic.GcRcZjQawu.png" height="35" width="35"></a></li>
  <li><a href="//soundcloud.com/uclsound"><img class="zero-bottom" alt="SoundCloud" src="//cdn.ucl.ac.uk/img/35x35xsoundcloud.png.pagespeed.ic.BdtBaqtDmd.jpg" height="35" width="35"></a></li>
  <li><a href="//www.flickr.com/photos/uclnews"><img class="zero-bottom" alt="Flickr" src="//cdn.ucl.ac.uk/img/35x35xflickr.png.pagespeed.ic.KdAnMQjbrP.png" height="35" width="35"></a></li>
  <li><a href="//www.instagram.com/ucl/"><img class="zero-bottom" alt="Instagram" src="//cdn.ucl.ac.uk/img/35x35xinstagram-badge.png.pagespeed.ic.OPAzj9OMyV.png" height="35" width="35"></a></li>
  <li><a href="//www.tiktok.com/@uclofficial"><img class="zero-bottom" alt="TikTok" src="//cdn.ucl.ac.uk/img/tiktok.png" height="35" width="35"></a></li>
</ul>
    <hr class="clear">
    <ul class="footer__list list-unstyled zero-bottom">
      <li class="footer__item text-muted small">University College London,&nbsp;Gower Street,&nbsp;London,&nbsp;WC1E 6BT&nbsp;Tel:&nbsp;+44&nbsp;(0)&nbsp;20 7679 2000</li>
    </ul>
    <ul class="list-inline footer__list list-unstyled list-inline--divided">
      <li class="text-muted small">Copyright © 2025 UCL</li>
      </li>
      <li class="small"><a href="//www.ucl.ac.uk/legal-services/disclaimer">Disclaimer</a>
      </li>
      <li class="small"><a href="//www.ucl.ac.uk/foi">Freedom of Information</a>
      </li>
      <li class="small"><a href="//www.ucl.ac.uk/accessibility">Accessibility</a>
      </li>
      <li class="small"><a href="//www.ucl.ac.uk/legal-services/privacy">Privacy and Cookies</a>
      </li>
      <li class="small"><a href="//www.ucl.ac.uk/commercial-procurement/modern-day-slavery-statement">Slavery statement</a>
      </li>
      <li class="small"><a href="//www.ucl.ac.uk/about/contact-us">Contact Us</a>
      </li>
    </ul>
  </div>
</footer>


  <script src="/research-computing-with-cpp/assets/js/lib/require.min.js"></script>
  <script src="/research-computing-with-cpp/assets/js/main.js"></script>
    <script>
      require.config({
        baseUrl: '/research-computing-with-cpp/assets/js/lib'
      });
        require(["app/general", "app/searchWithAutoComplete", "app/tabs"]);//load the default stuff
    </script>

</body>

</html>

