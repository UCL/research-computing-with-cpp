




<!DOCTYPE html>
<!--[if IE 7]> <html lang="en" class="lt-ie9 lt-ie8 no-js"> <![endif]-->
<!--[if IE 8]> <html lang="en" class="lt-ie9 no-js"> <![endif]-->
<!--[if gt IE 8]><!--> <html lang="en" class="no-js"> <!--<![endif]-->
<head>
    <meta charset=utf-8 />
    <meta name="author" content="UCL" />
    <meta name="description" content="UCL Homepage" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <!-- social meta -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@uclnews">
    <meta name="twitter:title" content="UCL - London's Global University">
    <meta name="twitter:description" content="UCL (University College London) is London's leading multidisciplinary university, with 8,000 staff and 25,000 students.">
    <meta name="twitter:creator" content="@UCLWAMS">
    <meta name="twitter:image:src" content="http://www.ucl.ac.uk/visual-identity/logos/standalone.png">
    <meta property="og:image" content="http://www.ucl.ac.uk/visual-identity/logos/standalone.png" />
    <meta property="og:title" content="UCL - London's Global University" />
    <meta property="og:url" content="http://www.ucl.ac.uk" />
    <meta property="og:site_name" content="UCL" />
    <meta property="og:description" content="UCL (University College London) is London's leading multidisciplinary university, with 8,000 staff and 25,000 students." />
    <meta property="og:type" content="website" />
    <meta property="og:profile_id" content="uclofficial" />
    <!-- end social meta -->

  <title>Cache Performance in Shared Memory</title>

  <link href="/research-computing-with-cpp/assets/css/screen.min.css" media="screen, projection" rel="stylesheet" type="text/css" />
  <link href="/research-computing-with-cpp/assets/css/jekyll-styles.css" rel="stylesheet" type="text/css">
  <link href="/research-computing-with-cpp/site-styles/local_styles.css" rel="stylesheet" type="text/css">
  <link href="/research-computing-with-cpp/site-styles/ipython.css" rel="stylesheet" type="text/css">

  <link rel="shortcut icon" href="/research-computing-with-cpp/assets/images/favicon.ico" />
    <link rel="apple-touch-icon-precomposed" href="/research-computing-with-cpp/favicon-152.png">
    <meta name="msapplication-TileColor" content="#000000">
    <meta name="msapplication-TileImage" content="/research-computing-with-cpp/favicon-144.png">

  <script src="/research-computing-with-cpp/assets/js/lib/modernizr-custom.js"></script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>

    <script>
      var cuttingTheMustard = document.querySelector && window.localStorage && window.addEventListener;

      Modernizr.load({
        //cutting the mustard as used by the BBC
        test: cuttingTheMustard
        //if old browser load the shiv
        ,
        nope: [
          '/research-computing-with-cpp/assets/js/lib/html5shiv-printshiv.min.js', '/research-computing-with-cpp/assets/js/lib/respond.min.js'
        ]
      });
      //set conditional assets for main.js
      var globalSiteSpecificVars = {
        pathToJquery: "/research-computing-with-cpp/assets/js/lib/jquery-1.9.1.min",
        googleAnalyticsIdsArray: [] //specify array of site specific id's NOT UCL generic UA-943297-1
      }
      if (cuttingTheMustard) {
        globalSiteSpecificVars.pathToJquery = '/research-computing-with-cpp/assets/js/lib/jquery-2.1.1.min';
      }
    </script>
    <script src="/research-computing-with-cpp/assets/js/lib/require.min.js"></script>
    <script src="/research-computing-with-cpp/assets/js/main.js"></script>
    <script>
      require.config({
        baseUrl: '/research-computing-with-cpp/assets/js/lib'
      });
        require(["app/general", "app/searchWithAutoComplete", "app/tabs"]);//load the default stuff
    </script>
</head>

<body id="index" class="layout-vertical layout-vertical--nav-1col">

  <header class="header header--desktop">

  <a class="header__close" href="#">
    <img src="/research-computing-with-cpp/assets/images/close.png" class="lazy" data-src="//static.ucl.ac.uk/indigo/images/close.png" alt="X" />Close</a>

  <div class="masthead">

  <div class="wrapper clearfix">

      <div class="masthead__search">
					<form action="#" method="get">
						<div class="search-form">
							<input type="search" placeholder="Search UCL websites, degrees, short courses, people and more" aria-label="Search UCL websites, degrees, short courses" class="search-form__input search-form__input--search tt-input" name="query" value="" autocomplete="off" spellcheck="false" dir="auto" style="position: relative; vertical-align: top;">
						</div>
						<input type="submit" name="submit" value="Go" class="btn btn--primary search-form__input search-form__input--submit">

					</form>
				</div>


				<nav class="masthead__nav m-clear">
					<ul class="masthead__list">
						<li class="masthead__item"><a href="//www.ucl.ac.uk/prospective-students" title="" class="masthead__link">Study</a>
						</li>
						<li class="masthead__item"><a href="//www.ucl.ac.uk/research" title="" class="masthead__link">Research</a>
						</li>
						<li class="masthead__item"><a href="//www.ucl.ac.uk/engage" title="" class="masthead__link">Engage</a>
						</li>

						<li class="masthead__item"><a href="//www.ucl.ac.uk/about" title="" class="masthead__link">About</a>
						</li>

						<li class="masthead__item"><a href="//www.ucl.ac.uk/giving" title="" class="masthead__link give-link">Give</a>
						</li>
					</ul>
				</nav>
			</div>

</div><!-- end .masthead -->


  <div class="wrapper">

    <div class="photograph">
  <div class="brand">
    <p class="brand__heading">COMP0210: Research Computing with C++</p>
    <a href="/" class="brand__link"><span class="visually-hidden">Home</span></a>
    <img src="//cdn.ucl.ac.uk/img/blank.gif" data-src="//static.ucl.ac.uk/indigo/images/ucl-logo.svg" alt="UCL logo" id="logo" class="brand__logo lazy">  
  </div>
</div>


    <div class="sidebar">

      <nav class="nav nav--mobile">
        <ul>
          

 <li class="active"> <a href="/research-computing-with-cpp/01projects/">Introduction to C++</a><ul><li class="inactive"> <a href="/research-computing-with-cpp/01projects/sec01Git.html">Version control with Git</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/01projects/sec02IntroToCpp.html">Introduction to C++</a> </li> </ul> </li><li class="active"> <a href="/research-computing-with-cpp/02cpp1/">Week 2: Custom Data Types and (a glimpse of) the Standard Library</a><ul><li class="inactive"> <a href="/research-computing-with-cpp/02cpp1/sec01Types.html">Types</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/02cpp1/sec02PassByValueOrReference.html">Pass by Value and Pass by Reference</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/02cpp1/sec03ObjectOrientedProgramming.html">Object Oriented Programming</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/02cpp1/sec04StandardLibrary.html">C++ Standard Library</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/02cpp1/sec05Pointers.html">Pointers in C++</a> </li> </ul> </li><li class="active"> <a href="/research-computing-with-cpp/03cpp2/">Week 3: Error Handling and C++ Projects</a><ul><li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec01Exceptions.html">Exceptions</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec02ErrorHandling.html">Other Error Mechanisms</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec03CMakeBasics.html">CMake Basics</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec04UnitTesting.html">Testing Software</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec05SoftwareBuilds.html">Building research software</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec06CMakeBackground.html">CMake Background</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec07CMakeHelloWorld.html">HelloWorld with CMake</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec08BuildHelloWorld.html">Building 'HelloWorld'</a> </li> </ul> </li><li class="active"> <a href="/research-computing-with-cpp/04cpp3/">Week 4: Polymorphism</a><ul><li class="inactive"> <a href="/research-computing-with-cpp/04cpp3/sec01Inheritance.html">Inheritance</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/04cpp3/sec03Templates.html">Templates</a> </li> </ul> </li> <li class="active"> <a href="/research-computing-with-cpp/05libraries/">Week 5: Code Design and Programming Paradigms</a><ul> <li class="inactive"> <a href="/research-computing-with-cpp/05libraries/ProgrammingParadigms.html">Programming Paradigms</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/05libraries/sec01DesigningClasses.html">Designing Classes and Code</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/05libraries/sec03CppCodeDesign.html">C++ Code Design Summary</a> </li> </ul> </li><li class="active"> <a href="/research-computing-with-cpp/06tooling/">Week 6: Libraries and Tooling</a><ul> <li class="inactive"> <a href="/research-computing-with-cpp/06tooling/sec00TimingAndTooling.html">Timing and Tooling</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/06tooling/sec01ChoosingLibraries.html">Choosing Libraries</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/06tooling/sec02LibraryBasics.html">Library Basics</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/06tooling/sec03LinkingLibraries.html">Linking Libraries</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/06tooling/sec04InstallingLibraries.html">Installing Libraries</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/06tooling/sec05Summary.html">Summary</a> </li></ul> </li> <li class="active"> <a href="/research-computing-with-cpp/07performance/">Week 7: Introduction to Performance</a><ul> <li class="inactive"> <a href="/research-computing-with-cpp/07performance/sec00Motivation.html">Why Optimise for Performance?</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/07performance/sec01Complexity.html">Computational Complexity</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/07performance/sec02Memory.html">Memory</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/07performance/sec03Optimisation.html">Compiler Optimisation</a> </li> </ul> </li><li class="active"> <a href="/research-computing-with-cpp/08openmp/">Week 8: Parallel Programming with OpenMP</a><ul><li class="active"> <a href="/research-computing-with-cpp/08openmp/01_parallel_programming.html">What is parallel programming?</a> </li> <li class="active"> <a href="/research-computing-with-cpp/08openmp/02_intro_openmp.html">An introduction to OpenMP</a> </li> <li class="active"> <a href="/research-computing-with-cpp/08openmp/04_cache_performance.html">Cache Performance in Shared Memory</a> </li> <li class="active"> <a href="/research-computing-with-cpp/08openmp/05_summary.html">Summary</a> </li></ul> </li> <li class="active"> <a href="/research-computing-with-cpp/09distributed_computing/">Week 9: Distributed Memory Parallelism</a><ul><li class="inactive"> <a href="/research-computing-with-cpp/09distributed_computing/sec01DistributedMemoryModels.html">Distributed Memory Model</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/09distributed_computing/sec02ProgrammingWithMPI.html">MPI Programming</a> </li> </ul> </li> <li class="active"> <a href="/research-computing-with-cpp/10parallel_algorithms/">Week 10: Work Depth Models and Parallel Strategies</a><ul> <li class="inactive"> <a href="/research-computing-with-cpp/10parallel_algorithms/AsynchronousMPI.html">Asynchronous MPI Programs</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/10parallel_algorithms/WorkDepth.html">Work Depth Models and Parallel Strategy</a> </li></ul> </li> 

        </ul>
      </nav>

      <nav class="nav nav--left">
        <ul>
          

 <li class="active"> <a href="/research-computing-with-cpp/01projects/">Introduction to C++</a><ul><li class="inactive"> <a href="/research-computing-with-cpp/01projects/sec01Git.html">Version control with Git</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/01projects/sec02IntroToCpp.html">Introduction to C++</a> </li> </ul> </li><li class="active"> <a href="/research-computing-with-cpp/02cpp1/">Week 2: Custom Data Types and (a glimpse of) the Standard Library</a><ul><li class="inactive"> <a href="/research-computing-with-cpp/02cpp1/sec01Types.html">Types</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/02cpp1/sec02PassByValueOrReference.html">Pass by Value and Pass by Reference</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/02cpp1/sec03ObjectOrientedProgramming.html">Object Oriented Programming</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/02cpp1/sec04StandardLibrary.html">C++ Standard Library</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/02cpp1/sec05Pointers.html">Pointers in C++</a> </li> </ul> </li><li class="active"> <a href="/research-computing-with-cpp/03cpp2/">Week 3: Error Handling and C++ Projects</a><ul><li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec01Exceptions.html">Exceptions</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec02ErrorHandling.html">Other Error Mechanisms</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec03CMakeBasics.html">CMake Basics</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec04UnitTesting.html">Testing Software</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec05SoftwareBuilds.html">Building research software</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec06CMakeBackground.html">CMake Background</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec07CMakeHelloWorld.html">HelloWorld with CMake</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/03cpp2/sec08BuildHelloWorld.html">Building 'HelloWorld'</a> </li> </ul> </li><li class="active"> <a href="/research-computing-with-cpp/04cpp3/">Week 4: Polymorphism</a><ul><li class="inactive"> <a href="/research-computing-with-cpp/04cpp3/sec01Inheritance.html">Inheritance</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/04cpp3/sec03Templates.html">Templates</a> </li> </ul> </li> <li class="active"> <a href="/research-computing-with-cpp/05libraries/">Week 5: Code Design and Programming Paradigms</a><ul> <li class="inactive"> <a href="/research-computing-with-cpp/05libraries/ProgrammingParadigms.html">Programming Paradigms</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/05libraries/sec01DesigningClasses.html">Designing Classes and Code</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/05libraries/sec03CppCodeDesign.html">C++ Code Design Summary</a> </li> </ul> </li><li class="active"> <a href="/research-computing-with-cpp/06tooling/">Week 6: Libraries and Tooling</a><ul> <li class="inactive"> <a href="/research-computing-with-cpp/06tooling/sec00TimingAndTooling.html">Timing and Tooling</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/06tooling/sec01ChoosingLibraries.html">Choosing Libraries</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/06tooling/sec02LibraryBasics.html">Library Basics</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/06tooling/sec03LinkingLibraries.html">Linking Libraries</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/06tooling/sec04InstallingLibraries.html">Installing Libraries</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/06tooling/sec05Summary.html">Summary</a> </li></ul> </li> <li class="active"> <a href="/research-computing-with-cpp/07performance/">Week 7: Introduction to Performance</a><ul> <li class="inactive"> <a href="/research-computing-with-cpp/07performance/sec00Motivation.html">Why Optimise for Performance?</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/07performance/sec01Complexity.html">Computational Complexity</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/07performance/sec02Memory.html">Memory</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/07performance/sec03Optimisation.html">Compiler Optimisation</a> </li> </ul> </li><li class="active"> <a href="/research-computing-with-cpp/08openmp/">Week 8: Parallel Programming with OpenMP</a><ul><li class="active"> <a href="/research-computing-with-cpp/08openmp/01_parallel_programming.html">What is parallel programming?</a> </li> <li class="active"> <a href="/research-computing-with-cpp/08openmp/02_intro_openmp.html">An introduction to OpenMP</a> </li> <li class="active"> <a href="/research-computing-with-cpp/08openmp/04_cache_performance.html">Cache Performance in Shared Memory</a> </li> <li class="active"> <a href="/research-computing-with-cpp/08openmp/05_summary.html">Summary</a> </li></ul> </li> <li class="active"> <a href="/research-computing-with-cpp/09distributed_computing/">Week 9: Distributed Memory Parallelism</a><ul><li class="inactive"> <a href="/research-computing-with-cpp/09distributed_computing/sec01DistributedMemoryModels.html">Distributed Memory Model</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/09distributed_computing/sec02ProgrammingWithMPI.html">MPI Programming</a> </li> </ul> </li> <li class="active"> <a href="/research-computing-with-cpp/10parallel_algorithms/">Week 10: Work Depth Models and Parallel Strategies</a><ul> <li class="inactive"> <a href="/research-computing-with-cpp/10parallel_algorithms/AsynchronousMPI.html">Asynchronous MPI Programs</a> </li> <li class="inactive"> <a href="/research-computing-with-cpp/10parallel_algorithms/WorkDepth.html">Work Depth Models and Parallel Strategy</a> </li></ul> </li> 

        </ul>
      </nav>

    </div>
    <!-- end .sidebar -->

    <nav class="nav nav--top">
      <ul>
        
      </ul>
    </nav>

  </div>
  <!-- end .wrapper -->

  </header>
  <!-- end .header -->

  <div class="site-content wrapper">

    <header class="header header--mobile default-header">
      <a class="header__open" href="#">
        <img src="/research-computing-with-cpp/assets/images/ucl-menu.svg" alt="Menu" />
      </a>
    </header>

    <div class="site-content__inner clearfix">
      <div class="site-content__body">

          
            <nav class="breadcrumb clearfix">
              <ul class="breadcrumb__list">
                <li class="breadcrumb__item"><a href="http://www.ucl.ac.uk/">UCL</a></li>

  
    <li class="breadcrumb__item"><a href="http://www.ucl.ac.uk/ISD">ISD</a></li>
  
    <li class="breadcrumb__item"><a href="http://www.ucl.ac.uk/isd/services">Our services</a></li>
  
    <li class="breadcrumb__item"><a href="http://www.ucl.ac.uk/isd/services/research-it">Research IT</a></li>
  
    <li class="breadcrumb__item"><a href="http://www.ucl.ac.uk/isd/services/research-it/training">Training</a></li>
  

<li class="breadcrumb__item"><a href="/research-computing-with-cpp/">COMP0210</a></li>



              </ul>
            </nav>
           <div class="site-content__main">
            
            
          
          

    <h1 id="cache-performance-in-shared-memory">Cache Performance in Shared Memory</h1>

<p>The need for cache efficiency hasn’t gone away just because we’ve started parallelising things; in fact, it may be more important than ever! Generally for distributed systems we just need to worry about the cache efficiency of each process in isolation, but if memory is shared then that means our cache gets shared too. The way that our cache behaves when shared is a little different though, so we’ll need to re-think how we do things a bit.</p>

<p>As always with the memory system, things will be system dependent, but on a typical CPU:</p>

<ul>
  <li>General RAM and the largest cache level will be shared between cores which share memory i.e. there
is just one physical RAM and one large physical cache (in my case just the L3 cache) which is
accessed by all cores. (Not all cores necessarily access memory with equal bandwidth or latency
though.)</li>
  <li>Each core will have its own copy of the smallest cache level(s), in my case it’s the L1 and L2 caches.</li>
  <li>
    <p>This keeps access to the small caches quick, but also enforces the need to consistency between the
copies of the caches.</p>

    <ul>
      <li>If I have two cores $C_1$ and $C_2$ which both store a copy of variable <code class="language-plaintext highlighter-rouge">x</code> in their L1 cache, then when they want to read <code class="language-plaintext highlighter-rouge">x</code> from memory they just read it from the cache and not from RAM. Likewise when they want to <em>write</em> to <code class="language-plaintext highlighter-rouge">x</code>, they write to the cache but not RAM.</li>
      <li>If $C_1$ changes <code class="language-plaintext highlighter-rouge">x</code>, it will change the value of <code class="language-plaintext highlighter-rouge">x</code> in <em>its own cache</em>, but not in the $C_2$ cache.</li>
      <li>In order for $C_2$ to read the correct value of <code class="language-plaintext highlighter-rouge">x</code> after the update, it has to find out about the change somehow.</li>
      <li>This mechanism will be system dependent but typically it will involve something written to a
special shared area (possibly part of the L3 cache) when $C_1$ updates <code class="language-plaintext highlighter-rouge">x</code>. $C_2$ needs to
check this and if <code class="language-plaintext highlighter-rouge">x</code> has been changed it needs to get the new value of <code class="language-plaintext highlighter-rouge">x</code> which will need to
be copied over, incurring additional overheads.</li>
    </ul>
  </li>
  <li>Remember that the cache stores data in blocks of a given size, called “cache lines”. The cache lines on my machine for example are 64 bytes or 8 doubles wide.</li>
  <li>
    <p>If two L1 caches on different cores both store the same cache line, and one of the cores changes
<em>any value in that line</em>, then <strong>the entire cache line is invalidated for the other core</strong>.</p>

    <ul>
      <li>This is extremely important as it means that even if the two cores never operate on the same values, if the values that they operate on are next to each other in memory and stored in the same cache line, then they will still invalidate one another’s caches and cause lookups to have to be made.</li>
    </ul>
  </li>
</ul>

<p>As a very simple example, let’s look at a possible manual implementation of the reduction code shown in last week’s class. I’ll do this example with no compiler optimisations to prevent the compiler optimising away any memory read/write operations so we have full control! As a reminder, the basic code looks like this:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;iostream&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;vector&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;cmath&gt;</span><span class="cp">
#include</span> <span class="cpf">"timer.hpp"</span><span class="cp">
#include</span> <span class="cpf">&lt;omp.h&gt;</span><span class="cp">
</span>
<span class="k">using</span> <span class="k">namespace</span> <span class="n">std</span><span class="p">;</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="k">const</span> <span class="kt">int</span> <span class="n">num_threads</span> <span class="o">=</span> <span class="n">omp_get_max_threads</span><span class="p">();</span>

  <span class="kt">double</span> <span class="n">sum</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">;</span>

  <span class="n">Timer</span> <span class="n">timer</span><span class="p">;</span>

<span class="cp">#pragma omp parallel for
</span>  <span class="k">for</span><span class="p">(</span><span class="kt">long</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">N</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">double</span> <span class="n">x</span> <span class="o">=</span> <span class="n">i</span><span class="o">*</span><span class="n">dx</span><span class="p">;</span>
    <span class="n">sum</span> <span class="o">+=</span> <span class="mf">4.0</span><span class="n">f</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span><span class="n">f</span> <span class="o">+</span> <span class="n">x</span><span class="o">*</span><span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="n">dx</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="kt">double</span> <span class="n">elapsed</span> <span class="o">=</span> <span class="n">timer</span><span class="p">.</span><span class="n">elapsed</span><span class="p">();</span>

  <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Time: "</span> <span class="o">&lt;&lt;</span> <span class="n">elapsed</span> <span class="o">&lt;&lt;</span> <span class="sc">'\n'</span><span class="p">;</span>
  <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Result: "</span> <span class="o">&lt;&lt;</span> <span class="n">sum</span> <span class="o">&lt;&lt;</span> <span class="sc">'\n'</span><span class="p">;</span>

  <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<ul>
  <li>We know that this loop is both slow and inaccurate because of the data race problems discussed last week.</li>
  <li>We can fix this using OMP’s built in reductions.</li>
  <li>Using 4 threads and the standard parallel sum reduction I get a time of 0.75 seconds for this sum. (My single threaded time is 2.05 seconds.)</li>
</ul>

<p>Let’s examine a simple reduction by hand though as an illustration of memory access patterns. We’ll allocate some memory to hold each of our partial sums, and then get each thread to only interact with its own partial sum, and add them all together at the end.</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="k">const</span> <span class="kt">long</span> <span class="n">N</span> <span class="o">=</span>   <span class="mi">1'000'000'000</span><span class="p">;</span>
  <span class="k">const</span> <span class="kt">double</span> <span class="n">dx</span> <span class="o">=</span> <span class="mf">1.0</span><span class="n">f</span><span class="o">/</span><span class="p">(</span><span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">);</span>
  <span class="k">const</span> <span class="kt">int</span> <span class="n">num_threads</span> <span class="o">=</span> <span class="n">omp_get_max_threads</span><span class="p">();</span>

  <span class="kt">double</span> <span class="n">sum</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">;</span>

  <span class="kt">double</span> <span class="o">*</span><span class="n">partial_sums</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">double</span><span class="p">[</span><span class="n">num_threads</span><span class="p">];</span>

  <span class="n">Timer</span> <span class="n">timer</span><span class="p">;</span>

  <span class="cp">#pragma omp parallel
</span>  <span class="p">{</span>
    <span class="kt">int</span> <span class="n">n</span> <span class="o">=</span> <span class="n">omp_get_thread_num</span><span class="p">();</span>
    <span class="n">partial_sums</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">;</span>

    <span class="cp">#pragma omp for
</span>    <span class="k">for</span><span class="p">(</span><span class="kt">long</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">N</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
      <span class="kt">double</span> <span class="n">x</span> <span class="o">=</span> <span class="n">i</span><span class="o">*</span><span class="n">dx</span><span class="p">;</span>
      <span class="n">partial_sums</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">+=</span> <span class="mf">4.0</span><span class="n">f</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span><span class="n">f</span> <span class="o">+</span> <span class="n">x</span><span class="o">*</span><span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="n">dx</span><span class="p">;</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_threads</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
  <span class="p">{</span>
    <span class="n">sum</span> <span class="o">+=</span> <span class="n">partial_sums</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
  <span class="p">}</span>

  <span class="kt">double</span> <span class="n">elapsed</span> <span class="o">=</span> <span class="n">timer</span><span class="p">.</span><span class="n">elapsed</span><span class="p">();</span>

  <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Time: "</span> <span class="o">&lt;&lt;</span> <span class="n">elapsed</span> <span class="o">&lt;&lt;</span> <span class="sc">'\n'</span><span class="p">;</span>
  <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Result: "</span> <span class="o">&lt;&lt;</span> <span class="n">sum</span> <span class="o">&lt;&lt;</span> <span class="sc">'\n'</span><span class="p">;</span>

  <span class="k">delete</span><span class="p">[]</span> <span class="n">partial_sums</span><span class="p">;</span>

  <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<ul>
  <li>My result is 3.14159, which is correct, which suggests that we have solved our data race problem.</li>
  <li>My time however is 2.10 seconds, so we’ve lost our performance boost! What is going on?</li>
  <li>Each of our partial sums is next to one another in memory, and could even all fit in the same cache line since there are only 4 doubles.</li>
  <li>Every time any thread updates its partial sum, any other thread whose partial sum is on the same cache line (which could be all of them!) will have its partial sum invalidated leading to a slower memory access.</li>
  <li>This overhead is incurred at every single step in our loop for every thread!</li>
</ul>

<p>We can show that this is the problem by moving our variables to separate cache lines. We can force this to happen by buffering our partial sum array, since the array has to be contiguous. In my case, my cache is 64 bytes or 8 doubles wide, so we have to make sure there is an extra 7 doubles worth of space between each value in memory.</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
  <span class="k">const</span> <span class="kt">long</span> <span class="n">N</span> <span class="o">=</span>   <span class="mi">1'000'000'000</span><span class="p">;</span>
  <span class="k">const</span> <span class="kt">double</span> <span class="n">dx</span> <span class="o">=</span> <span class="mf">1.0</span><span class="n">f</span><span class="o">/</span><span class="p">(</span><span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">);</span>
  <span class="k">const</span> <span class="kt">int</span> <span class="n">num_threads</span> <span class="o">=</span> <span class="n">omp_get_max_threads</span><span class="p">();</span>

  <span class="kt">double</span> <span class="n">sum</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">;</span>

  <span class="kt">int</span> <span class="n">LINE_SIZE</span> <span class="o">=</span> <span class="mi">8</span><span class="p">;</span>
  <span class="kt">double</span> <span class="o">*</span><span class="n">partial_sums</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">double</span><span class="p">[</span><span class="n">num_threads</span><span class="o">*</span><span class="mi">8</span><span class="p">];</span>

  <span class="n">Timer</span> <span class="n">timer</span><span class="p">;</span>

  <span class="cp">#pragma omp parallel
</span>  <span class="p">{</span>
    <span class="kt">int</span> <span class="n">n</span> <span class="o">=</span> <span class="n">omp_get_thread_num</span><span class="p">()</span><span class="o">*</span><span class="mi">8</span><span class="p">;</span>
    <span class="n">partial_sums</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">;</span>

    <span class="cp">#pragma omp for
</span>    <span class="k">for</span><span class="p">(</span><span class="kt">long</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">N</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
      <span class="kt">double</span> <span class="n">x</span> <span class="o">=</span> <span class="n">i</span><span class="o">*</span><span class="n">dx</span><span class="p">;</span>
      <span class="n">partial_sums</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">+=</span> <span class="mf">4.0</span><span class="n">f</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span><span class="n">f</span> <span class="o">+</span> <span class="n">x</span><span class="o">*</span><span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="n">dx</span><span class="p">;</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">num_threads</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
  <span class="p">{</span>
    <span class="n">sum</span> <span class="o">+=</span> <span class="n">partial_sums</span><span class="p">[</span><span class="mi">8</span><span class="o">*</span><span class="n">i</span><span class="p">];</span>
  <span class="p">}</span>

  <span class="kt">double</span> <span class="n">elapsed</span> <span class="o">=</span> <span class="n">timer</span><span class="p">.</span><span class="n">elapsed</span><span class="p">();</span>

  <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Time: "</span> <span class="o">&lt;&lt;</span> <span class="n">elapsed</span> <span class="o">&lt;&lt;</span> <span class="sc">'\n'</span><span class="p">;</span>
  <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Result: "</span> <span class="o">&lt;&lt;</span> <span class="n">sum</span> <span class="o">&lt;&lt;</span> <span class="sc">'\n'</span><span class="p">;</span>

  <span class="k">delete</span><span class="p">[]</span> <span class="n">partial_sums</span><span class="p">;</span>

  <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</code></pre></div></div>

<ul>
  <li>By placing each partial sum 8 elements apart instead of 1 element apart, we force each value to exist on a different cache line.</li>
  <li>Now all my partial sums can be in the cache at the same time <em>and</em> updating them will not interfere with one another at all.</li>
  <li>My time for this sum with four cores is 0.84s, almost back down to our OMP reduction time.</li>
</ul>

<p>The additional overhead is for the dereferencing operations, since we haven’t compiled with optimisations. If for example we introduce a private variable to dereference the memory outside the for loop:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="cp">#pragma omp parallel
</span>  <span class="p">{</span>
    <span class="kt">int</span> <span class="n">n</span> <span class="o">=</span> <span class="n">omp_get_thread_num</span><span class="p">()</span><span class="o">*</span><span class="mi">8</span><span class="p">;</span>
    <span class="kt">double</span> <span class="o">&amp;</span><span class="n">private_sum</span> <span class="o">=</span> <span class="n">partial_sums</span><span class="p">[</span><span class="n">n</span><span class="p">];</span>
    <span class="n">private_sum</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">;</span>

    <span class="cp">#pragma omp for
</span>    <span class="k">for</span><span class="p">(</span><span class="kt">long</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">N</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
      <span class="kt">double</span> <span class="n">x</span> <span class="o">=</span> <span class="n">i</span><span class="o">*</span><span class="n">dx</span><span class="p">;</span>
      <span class="n">private_sum</span> <span class="o">+=</span> <span class="mf">4.0</span><span class="n">f</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span><span class="n">f</span> <span class="o">+</span> <span class="n">x</span><span class="o">*</span><span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="n">dx</span><span class="p">;</span>
    <span class="p">}</span>
  <span class="p">}</span>
</code></pre></div></div>

<p>then my time drops back down to 0.75 seconds.</p>

<p>Don’t worry too much if your threads access <em>some</em> memory that lies next to memory accessed by another thread - most problems will have to divide up memory in a way that shares some kind of boundary! But if your threads are spending a lot of time accessing memory next to one another it can cause serious performance issues. Having thread work on contiguous blocks of data in an array for example is better than having threads work on data that is interleaved with other threads.</p>



        </div>

      </div>
    </div>

  </div>
  <!-- end .site-content -->

  <footer class="footer wrapper">
  <div class="footer__inner clearfix">
             <article class="block block--col-1">
                <h2 class="as-h5">Information for</h2>
                <ul class="footer__list list-unstyled">
					<li class="footer__item"><a href="//www.ucl.ac.uk/students">Current students</a></li>
					<li class="footer__item"><a href="//www.ucl.ac.uk/staff">Staff</a></li>
					<li class="footer__item"><a href="//www.ucl.ac.uk/alumni">Alumni</a></li>
					<li class="footer__item"><a href="//www.ucl.ac.uk/enterprise/businesses">Business</a></li>
					<li class="footer__item"><a href="//www.ucl.ac.uk/giving">Donors</a></li>
				</ul>
            </article>
            <article class="block block--col-2">
		<h2 class="as-h5">Visit</h2>
                <ul class="footer__list list-unstyled">
					<li class="footer__item"><a href="//www.ucl.ac.uk/maps">Maps</a></li>
					<li class="footer__item"><a href="//www.ucl.ac.uk/lccos/library-culture-collections-and-open-science-lccos">Library, museums and collections</a></li>
					<li class="footer__item"><a href="//www.ucl.ac.uk/bloomsbury-theatre">Bloomsbury Theatre</a></li>
					<li class="footer__item"><a href="//www.ucl.ac.uk/ucl-east">UCL East</a></li>
					<li class="footer__item"><a href="//www.ucl.ac.uk/maps">Tours and visits</a></li>

				</ul>
            </article>
            <article class="block block--col-3">
		<h2 class="as-h5">Connect with UCL</h2>
                <ul class="footer__list list-unstyled">
					<li class="footer__item"><a href="//www.ucl.ac.uk/work-at-ucl/search-ucl-jobs">Jobs</a></li>
					<li class="footer__item"><a href="//www.ucl.ac.uk/news/services-media">Media Relations</a></li>
					<li class="footer__item"><a href="//www.ucl.ac.uk/events">Events</a></li>
					<li class="footer__item"><a href="//www.ucl.ac.uk/london">UCL and London</a></li>
					<li class="footer__item"><a href="//shop.ucl.ac.uk">UCL Shop</a></li>
				</ul>

      </article>
<div class="clear"></div>
<ul id="social" class="list-inline footer__list list-unstyled zero-bottom">
  <li><a href="//twitter.com/ucl"><img class="zero-bottom" alt="Twitter" src="//cdn.ucl.ac.uk/img/twitter-x.png" height="35" width="35"></a></li>
  <li><a href="//www.facebook.com/uclofficial"><img class="zero-bottom" alt="Facebook" src="//cdn.ucl.ac.uk/img/35x35xfacebook.png.pagespeed.ic.-VUStBF1gm.png" height="35" width="35"></a></li>
  <li><a href="//www.youtube.com/ucltv"><img class="zero-bottom" alt="YouTube" src="//cdn.ucl.ac.uk/img/35x35xyoutube-icon-square.png.pagespeed.ic.GcRcZjQawu.png" height="35" width="35"></a></li>
  <li><a href="//soundcloud.com/uclsound"><img class="zero-bottom" alt="SoundCloud" src="//cdn.ucl.ac.uk/img/35x35xsoundcloud.png.pagespeed.ic.BdtBaqtDmd.jpg" height="35" width="35"></a></li>
  <li><a href="//www.flickr.com/photos/uclnews"><img class="zero-bottom" alt="Flickr" src="//cdn.ucl.ac.uk/img/35x35xflickr.png.pagespeed.ic.KdAnMQjbrP.png" height="35" width="35"></a></li>
  <li><a href="//www.instagram.com/ucl/"><img class="zero-bottom" alt="Instagram" src="//cdn.ucl.ac.uk/img/35x35xinstagram-badge.png.pagespeed.ic.OPAzj9OMyV.png" height="35" width="35"></a></li>
  <li><a href="//www.tiktok.com/@uclofficial"><img class="zero-bottom" alt="TikTok" src="//cdn.ucl.ac.uk/img/tiktok.png" height="35" width="35"></a></li>
</ul>
    <hr class="clear">
    <ul class="footer__list list-unstyled zero-bottom">
      <li class="footer__item text-muted small">University College London,&nbsp;Gower Street,&nbsp;London,&nbsp;WC1E 6BT&nbsp;Tel:&nbsp;+44&nbsp;(0)&nbsp;20 7679 2000</li>
    </ul>
    <ul class="list-inline footer__list list-unstyled list-inline--divided">
      <li class="text-muted small">Copyright © 2025 UCL</li>
      </li>
      <li class="small"><a href="//www.ucl.ac.uk/legal-services/disclaimer">Disclaimer</a>
      </li>
      <li class="small"><a href="//www.ucl.ac.uk/foi">Freedom of Information</a>
      </li>
      <li class="small"><a href="//www.ucl.ac.uk/accessibility">Accessibility</a>
      </li>
      <li class="small"><a href="//www.ucl.ac.uk/legal-services/privacy">Privacy and Cookies</a>
      </li>
      <li class="small"><a href="//www.ucl.ac.uk/commercial-procurement/modern-day-slavery-statement">Slavery statement</a>
      </li>
      <li class="small"><a href="//www.ucl.ac.uk/about/contact-us">Contact Us</a>
      </li>
    </ul>
  </div>
</footer>


  <script src="/research-computing-with-cpp/assets/js/lib/require.min.js"></script>
  <script src="/research-computing-with-cpp/assets/js/main.js"></script>
    <script>
      require.config({
        baseUrl: '/research-computing-with-cpp/assets/js/lib'
      });
        require(["app/general", "app/searchWithAutoComplete", "app/tabs"]);//load the default stuff
    </script>

</body>

</html>

